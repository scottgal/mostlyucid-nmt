# Docker Compose - GPU optimized with 15 cached models
#
# Usage:
#   docker compose -f docker-compose.gpu.yml up -d
#
# Requirements:
#   - NVIDIA GPU with 8GB+ VRAM (15 Opus-MT models ≈ 4.5GB in FP16)
#   - NVIDIA Container Toolkit installed
#   - nvidia-docker2 or Docker 19.03+ with --gpus support
#
# Model cache is persisted to ./model-cache for fast restarts

services:
  nmt:
    image: scottgal/mostlylucid-nmt:gpu
    # Or build locally:
    # build:
    #   context: .
    #   dockerfile: Dockerfile.gpu.min
    container_name: nmt-gpu
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      # Persist models between restarts (avoids re-downloading)
      - ./model-cache:/app/models

    # GPU access
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 16G
        # reservations:
        #   memory: 8G

    environment:
      # ═══════════════════════════════════════════════════════════════════
      # DEVICE SETTINGS
      # ═══════════════════════════════════════════════════════════════════
      USE_GPU: "true"
      DEVICE: "cuda:0"
      # For multi-GPU, uncomment and adjust:
      # CUDA_VISIBLE_DEVICES: "0,1"

      # ═══════════════════════════════════════════════════════════════════
      # MODEL CACHE - 15 models in VRAM
      # ═══════════════════════════════════════════════════════════════════
      MAX_CACHED_MODELS: "15"
      MODEL_CACHE_DIR: "/app/models"

      # Preload common pairs at startup (loaded into GPU memory immediately)
      PRELOAD_MODELS: "en->de,de->en,en->fr,fr->en,en->es,es->en,en->it,it->en"

      # ═══════════════════════════════════════════════════════════════════
      # GPU OPTIMIZATION - Single worker, large batches, FP16
      # ═══════════════════════════════════════════════════════════════════
      # Single Gunicorn worker (GPU serialization, no contention)
      WEB_CONCURRENCY: "1"

      # Single translation at a time (GPU handles batching internally)
      MAX_INFLIGHT_TRANSLATIONS: "1"

      # Large batch size - GPU excels at parallel tensor ops
      EASYNMT_BATCH_SIZE: "64"

      # FP16 halves memory usage, 2x+ throughput on modern GPUs
      EASYNMT_MODEL_ARGS: '{"torch_dtype":"fp16"}'

      # ═══════════════════════════════════════════════════════════════════
      # QUEUE MANAGEMENT
      # ═══════════════════════════════════════════════════════════════════
      ENABLE_QUEUE: "1"
      MAX_QUEUE_SIZE: "2000"
      TRANSLATE_TIMEOUT_SEC: "120"

      # ═══════════════════════════════════════════════════════════════════
      # MEMORY MANAGEMENT
      # ═══════════════════════════════════════════════════════════════════
      ENABLE_MEMORY_MONITOR: "1"

      # GPU VRAM thresholds
      GPU_MEMORY_WARNING_THRESHOLD: "75"
      GPU_MEMORY_CRITICAL_THRESHOLD: "85"

      # RAM thresholds (models also use system RAM for loading)
      MEMORY_WARNING_THRESHOLD: "80"
      MEMORY_CRITICAL_THRESHOLD: "90"

      # Evict idle models after 1 hour to free VRAM
      MODEL_IDLE_TIMEOUT: "3600"
      IDLE_CHECK_INTERVAL: "60"

      # Clear CUDA cache periodically (reduces fragmentation)
      CUDA_CACHE_CLEAR_INTERVAL_SEC: "300"

      # ═══════════════════════════════════════════════════════════════════
      # MODEL FAMILY & FALLBACK
      # ═══════════════════════════════════════════════════════════════════
      MODEL_FAMILY: "opus-mt"
      AUTO_MODEL_FALLBACK: "1"
      PIVOT_FALLBACK: "1"
      PIVOT_LANG: "en"

      # ═══════════════════════════════════════════════════════════════════
      # MARKDOWN SANITIZATION (for translated markdown content)
      # ═══════════════════════════════════════════════════════════════════
      MARKDOWN_SANITIZE: "1"
      MARKDOWN_SAFE_MODE_AUTO: "1"
      MARKDOWN_MAX_DEPTH: "10"

      # ═══════════════════════════════════════════════════════════════════
      # LOGGING
      # ═══════════════════════════════════════════════════════════════════
      LOG_LEVEL: "INFO"
      REQUEST_LOG: "1"
      LOG_FORMAT: "plain"

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
